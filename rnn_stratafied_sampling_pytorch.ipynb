{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2239b",
   "metadata": {
    "id": "96c2239b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b15d26",
   "metadata": {
    "id": "98b15d26"
   },
   "outputs": [],
   "source": [
    "n_letters = 58\n",
    "n_categories = 18\n",
    "n_hidden = 128\n",
    "n_epochs = 100\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "learning_rate = 0.00001  # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape (int): size of the 1-hot embeddings for each character (this will be 58)\n",
    "            hidden_layer_width (int): number of nodes in the single hidden layer within the model\n",
    "            n_classes (int): number of output classes\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.W_U_h = nn.Linear(input_size + hidden_size, hidden_size, bias=True)\n",
    "        self.W_U_y = nn.Linear(input_size + hidden_size, output_size, bias=True)\n",
    "\n",
    "        self.softmax_fnc = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \"\"\"Forward function accepts tensor of input data, returns tensor of output data.\n",
    "        Modules defined in constructor are used, along with arbitrary operators on tensors\n",
    "        \"\"\"\n",
    "\n",
    "        input_cat_hidden = torch.hstack((input, hidden))\n",
    "\n",
    "        # input_cat_hidden = input_cat_hidden.squeeze()\n",
    "\n",
    "        h_t = self.W_U_h(input_cat_hidden)\n",
    "\n",
    "        y_t = self.softmax_fnc(self.W_U_y(input_cat_hidden))\n",
    "\n",
    "        # y_t = y_t.squeeze()\n",
    "\n",
    "        # your function will return the output y(t) and hidden h(t) from equation 1 in the docs\n",
    "        #         print('h_t')\n",
    "        #         print(h_t.shape)\n",
    "        #         print('y_t')\n",
    "        #         print(y_t.shape)\n",
    "        #         print('self.W_U_h.weight')\n",
    "        #         print(self.W_U_h.weight.shape)\n",
    "        #         print('input')\n",
    "        #         print(input.shape)\n",
    "        #         print('hidden')\n",
    "        #         print(hidden.shape)\n",
    "        #         print('input_cat_hidden')\n",
    "        #         print(input_cat_hidden.shape)\n",
    "        return y_t, h_t\n",
    "\n",
    "    def initHidden(self):\n",
    "        \"\"\"\n",
    "        This function initializes the first hidden state of the RNN as a zero tensor.\n",
    "        \"\"\"\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "def get_xy_pairs(names):\n",
    "    # process the names dict and convert into a list of (x,y) pairs. x is a 1-hot tensor of size (num_characters_in_name, 1, n_letters)\n",
    "    # y is a scalar representing the category of the language, there are 18 languages, assign an index between 0-17 to each language and y represents this index.\n",
    "    # you may make use of the nameToTensor() function in the utils.py file to help you with this function\n",
    "\n",
    "    list_of_pairs = []\n",
    "\n",
    "    i = 0\n",
    "    for language, list_of_names in names.items():\n",
    "        for name in list_of_names:\n",
    "            curr_x = nameToTensor(name)\n",
    "            list_of_pairs.append([curr_x, i])\n",
    "        i += 1\n",
    "\n",
    "    return list_of_pairs\n",
    "\n",
    "\n",
    "def create_train_and_test_set(list_of_pairs):\n",
    "    # uses over and under sampling\n",
    "\n",
    "    num_pairs = len(list_of_pairs)\n",
    "\n",
    "    strata_dict = {}\n",
    "    for i in range(num_pairs):\n",
    "      if (list_of_pairs[i][1] not in strata_dict.keys()):\n",
    "        strata_dict[list_of_pairs[i][1]] = []\n",
    "        strata_dict[list_of_pairs[i][1]].append(list_of_pairs[i])\n",
    "      else:\n",
    "        strata_dict[list_of_pairs[i][1]].append(list_of_pairs[i]) \n",
    "    \n",
    "    sum = 0\n",
    "    min_length = float('INF')\n",
    "    for key in strata_dict:\n",
    "      random.shuffle(strata_dict[key]) \n",
    "      if (len(strata_dict[key]) < min_length):\n",
    "        min_length = len(strata_dict[key])\n",
    "      sum += len(strata_dict[key])\n",
    "\n",
    "    per_lang_data_length = sum // len(strata_dict.keys())\n",
    "  \n",
    "    for key in strata_dict:\n",
    "      if len(strata_dict[key]) > per_lang_data_length:\n",
    "        del strata_dict[key][per_lang_data_length:]\n",
    "      else:\n",
    "        while (len(strata_dict[key]) < per_lang_data_length):\n",
    "          strata_dict[key].append(random.choice(strata_dict[key]))\n",
    "    \n",
    "    list_of_pairs = []\n",
    "    for key in strata_dict:\n",
    "      for pair in strata_dict[key]:\n",
    "        list_of_pairs.append(pair)\n",
    "    \n",
    "    random.shuffle(list_of_pairs)\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "\n",
    "    num_pairs = len(list_of_pairs)\n",
    "    cut_off = int(0.2 * num_pairs)\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        if (i > cut_off):\n",
    "            train_x.append(list_of_pairs[i][0])\n",
    "            train_y.append(torch.tensor(list_of_pairs[i][1]))\n",
    "        else:\n",
    "            test_x.append(list_of_pairs[i][0])\n",
    "            test_y.append(torch.tensor(list_of_pairs[i][1]))\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "def train(train_x, train_y):\n",
    "    \"\"\"train_x and train_y are lists with names and correspoonding labels\"\"\"\n",
    "    loss = 0\n",
    "    for x, y in zip(train_x, train_y):\n",
    "        hidden = rnn.initHidden()\n",
    "        for i in range(x.size()[0]):\n",
    "            output, hidden = rnn(x[i], hidden)\n",
    "        # print(torch.log(output))\n",
    "        # print(y.unsqueeze(0))\n",
    "        # loss += criterion(torch.log(torch.add(output, 1e-20)),\n",
    "        #                   y.unsqueeze(0))  # the unsqueeze converts the scalar y to a 1D tensor\n",
    "        loss += criterion(torch.log(output), y.unsqueeze(0))  # the unsqueeze converts the scalar y to a 1D tensor\n",
    "        # if epochnum > 3:\n",
    "        #     print(output)\n",
    "        #     print(y)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(train_x, train_y):\n",
    "    \"\"\"train_x and train_y are lists with names and correspoonding labels\"\"\"\n",
    "    loss = 0\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in zip(train_x, train_y):\n",
    "            hidden = rnn.initHidden()\n",
    "            for i in range(x.size()[0]):\n",
    "                output, hidden = rnn(x[i], hidden)\n",
    "            pred_labels.append(output)\n",
    "            loss += criterion(torch.log(torch.add(output, 1e-20)),\n",
    "                              y.unsqueeze(0))  # the unsqueeze converts the scalar y to a 1D tensor\n",
    "    return loss, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afb08d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "e6afb08d",
    "outputId": "686c3edd-5108-4fdc-cae5-9b85dd9b621e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss = tensor(11636.8320)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9dbc42483827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcurrent_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcurrent_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_pred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mall_train_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_train_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-6659ae5ee9d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m\"\"\"train_x and train_y are lists with names and correspoonding labels\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Keep track of losses for plotting\n",
    "current_test_loss = 0\n",
    "current_train_loss = 0\n",
    "all_train_losses = []\n",
    "all_test_losses = []\n",
    "all_pred_labels = []\n",
    "\n",
    "#names is your dataset in python dictionary form. Keys are languages and values are list of words belonging to that language\n",
    "with open('names.json', 'r') as fp:\n",
    "    names = json.load(fp)\n",
    "\n",
    "list_of_pairs = get_xy_pairs(names)\n",
    "train_x, train_y, test_x, test_y = create_train_and_test_set(list_of_pairs)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    current_train_loss = train(train_x, train_y)\n",
    "    current_test_loss, curr_pred_labels = test(test_x, test_y)\n",
    "    all_train_losses.append(current_train_loss)\n",
    "    all_test_losses.append(current_test_loss)\n",
    "    all_pred_labels.append(curr_pred_labels)\n",
    "    # for name, param in rnn.named_parameters():\n",
    "    #   if param.requires_grad:\n",
    "    #     print(name, param.data)\n",
    "    print('epoch: ' + str(epoch) + ', loss = ' + str(current_test_loss))\n",
    "    \n",
    "\n",
    "#saving your model\n",
    "# torch.save(rnn, 'rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LU_D4lW2730x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "LU_D4lW2730x",
    "outputId": "aa7c3c98-76a1-40ff-de70-1546f7f9a540"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train = []\n",
    "for tensor in all_train_losses:\n",
    "  y_train.append(tensor.item())\n",
    "\n",
    "y_test = []\n",
    "for tensor in all_test_losses:\n",
    "  y_test.append(tensor.item())\n",
    "\n",
    "x = range(len(y_train))\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"\")\n",
    "plt.plot(x, y_train)\n",
    "plt.plot(x, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch (Python 3.9 w/ PyTorch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
